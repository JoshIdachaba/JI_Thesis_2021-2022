{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity Analysis ##\n",
    "\n",
    "The following function performs a cosine similarity analysis of a subset 'subset' of the FDC Global Branded Food Products \n",
    "    Database (GBFPD), assuming it's saved to path as 'branded_food.csv'. The cosine_similarity_analysis function takes \n",
    "    three arguments (all string arguments):\n",
    "\n",
    "* **filename**, which corresponds to the file path of the GBFPD (assumed to be downloaded to computer. In this example, **filename** is set to \"branded_food.csv\", assuming that the dataset is in the same directory as this file.\n",
    "* **subset** , which refers to the branded food category to be queried in step 2. **subset** is set to \"Rice\" for this demonstration of the analysis\n",
    "* **label_color**, which refers to the color used for the points in the graph. This can be set to a hex code (e.g., #OOOFFF) or a named color (Visit https://matplotlib.org/stable/gallery/color/named_colors.html for a list of named colors). For this file, **label_color** is set to \"blue\" \n",
    "\n",
    "This function assumes that the dataset used is the USDA Global Branded Food Product Database (GBFPD), which can be downloaded from https://fdc.nal.usda.gov/download-datasets.html  as \"branded_food.csv\". This function also assumes that \"branded_food.csv\" is installed on your computer at the path **filename**. This function also assumes that **subset** is a valid value of the column \"branded_food_category\".\n",
    "\n",
    "You can check the domain of the column \"branded_food_category\" with the following lines of code(given that 'branded_food.csv' is in the same folder as this notebook):\n",
    "\n",
    "**df = pd.read_csv(\"branded_food.csv\", low_memory = False)** \n",
    "\n",
    "**y = \"Some string\"** (replace \"Some string\" with a string of your choice, checking if that string is a valid value of branded_food_category)\n",
    "\n",
    "**print(y in df['branded_food_category'].unique())**\n",
    "\n",
    "\n",
    "\n",
    "This function involves the following 16 steps:\n",
    "1. Import Food Data Central Food Products Database\n",
    "2. Get subset matching branded_food_category == **subset**\n",
    "3. Calculate and get Readability Scores for FoodData Central ingredient lists\n",
    "4. Generate Matrix of pairwise differences for Flesch Reading Ease\n",
    "5. Create Difference Matrix- Dale-Chall Index\n",
    "6. Convert FDC IDs from float to string\n",
    "7. Create list of all possible FDC ID pairs (repeating)\n",
    "8. Create and fit CountVectorizer model to ingredient lists \n",
    "9. Transform CountVectorizer model to array\n",
    "10. Calculate cosine similarity of ingredient lists\n",
    "11. Create Dataframe with readability differences and cosine similarities\n",
    "12. Prepare dataframe for plot generation and Summary Statistics\n",
    "13. Get Scatter Plot- Dale Chall diff vs Cosine Similarity\n",
    "14. Get Scatter Plot- Dale Chall diff vs Flesch diff\n",
    "15. Get Scatter Plot- Flesch diff vs Cosine Similarity\n",
    "16. Get Pearson Correlations via scipy.stats.pearsonr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages Used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import readability\n",
    "import time\n",
    "import numbers\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "import itertools\n",
    "from itertools import combinations,chain,product,permutations\n",
    "from batch_test import batchCosineSimilarity\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import Food Data Central Food Products Database \n",
    "FoodDataCentral = pd.read_csv(\"branded_food.csv\", low_memory = False)\n",
    "subset = \"Rice\"\n",
    "label_color = \"blue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate list of branded food categories (Optional, can be used to determine branded food category for analysis, if applicable)\n",
    "grouped_counts = pd.DataFrame(FoodDataCentral.groupby(['branded_food_category'])['branded_food_category'].count())\n",
    "grouped_counts.columns = [\"bfc_count\"]\n",
    "grouped_counts.sort_values(by = \"bfc_count\", ascending = False)[50:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Get Database subset by branded food category ('Rice' in this case) and remove rows with empty values or only non-words \n",
    "#FoodDataCentral = FoodDataCentral.query(\"branded_food_category == 'Rice'\")\n",
    "if isinstance(subset, numbers.Number):\n",
    "        delim_subset = \"Random\"\n",
    "        FoodDataCentral = FoodDataCentral.sample(n=subset, random_state=11)\n",
    "    else:\n",
    "        FDC_query = \"\".join((\"branded_food_category == '\",subset,\"'\")) #Note: subset must be in the domain of 'branded_food_category', or else a ValueError is raised.\n",
    "        delim_subset = subset.replace(\" \",\"-\")\n",
    "        FoodDataCentral = FoodDataCentral.query(FDC_query)\n",
    "    \n",
    "    \n",
    "    FoodDataCentral = FoodDataCentral.dropna(subset = ['ingredients'])\n",
    "    FoodDataCentral = FoodDataCentral[FoodDataCentral[\"ingredients\"] != \"---\"]\n",
    "    FoodDataCentral = FoodDataCentral[FoodDataCentral[\"ingredients\"] != \",\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Calculate and get Readability Scores for FoodData Central ingredient lists\n",
    "readability_scores = []\n",
    "    for index, row in FoodDataCentral.iterrows():\n",
    "        \n",
    "        #Get ingredient list and convert to lowercase string (required to calculate syllables in readability.getmeasures())\n",
    "        ingredients = row[\"ingredients\"]\n",
    "        ingredients = ingredients.lower()\n",
    "        \n",
    "        # Set ingredient lists with incalculable readability to NA\n",
    "        if pd.isna(ingredients) or ingredients in [\"---\",\",\"]:\n",
    "            curr_record = (row['fdc_id'], row['gtin_upc'], pd.NA,pd.NA)\n",
    "            readability_scores.append(curr_record)\n",
    "\n",
    "        else:\n",
    "            \"\"\"Readability.getmeasures() automatically tokenizes the input using spaces as a delimiter for words and /n as a delimiter for sentences. \n",
    "                The function then calculates and returns a set of readability measures. In this case,\n",
    "                we are getting specific measures from the set (Flesch Reading Ease and Dale-Chall Readability) \"\"\"\n",
    "            \n",
    "            #Prepare data for readability measurement\n",
    "            token_ing = word_tokenize(ingredients)\n",
    "            ingredients = token_ing\n",
    "            \n",
    "            #Get readability measures\n",
    "            measures = readability.getmeasures(ingredients)\n",
    "            curr_record = (row['fdc_id'], row['gtin_upc'], row['branded_food_category'],row['ingredients'],\n",
    "                           measures['readability grades']['Kincaid'],\n",
    "                           measures['readability grades']['FleschReadingEase'],\n",
    "                           measures['readability grades']['DaleChallIndex'],\n",
    "                           measures['sentence info']['words'],\n",
    "                           measures['sentence info']['complex_words_dc'])\n",
    "            readability_scores.append(curr_record)\n",
    "\n",
    "    #Gather data in Pandas DataFrame\n",
    "    readScores_FDC = pd.DataFrame(data = readability_scores, columns = [\"fdc_id\", \"gtin_upc\",\"branded_food_category\",\"ingredients\",\n",
    "                                                                        \"Kincaid_Score\",\"FleschReadingEase\",\"DaleChallIndex\",\n",
    "                                                                        \"num_words\",\"complex_words_dc\"])\n",
    "    #Remove NAs and save dataset to CSV\n",
    "    readScores_FDC = readScores_FDC.dropna()\n",
    "    readScores_FDC.to_csv(\"\".join((delim_subset,\"_FoodData_Central_Readability.csv\")), sep=\",\")\n",
    "    FoodDataCentral = readScores_FDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Generate Matrix of pairwise differences for Flesch Reading Ease, as a 1-d list\n",
    "difference_matrix_fl = [[abs(y - x) for x in FoodDataCentral[\"FleschReadingEase\"]] for y in FoodDataCentral[\"FleschReadingEase\"]]\n",
    "difference_matrix_fl = list(chain(*difference_matrix_fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Generate Matrix of pairwise differences for Dale Chall Readability, as a 1-d list\n",
    "difference_matrix_dc = [[abs(y - x) for x in FoodDataCentral[\"DaleChallIndex\"]] for y in FoodDataCentral[\"DaleChallIndex\"]]\n",
    "difference_matrix_dc = list(chain(*difference_matrix_dc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Convert FDC IDs from float to string\n",
    "FoodDataCentral[\"fdc_id\"] = FoodDataCentral[\"fdc_id\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get FDC indices for referencing matrices (Optional)\n",
    "#fdc_indices = dict(enumerate(FoodDataCentral[\"fdc_id\"]))\n",
    "#print(fdc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Create list of FDC ID pairs (w/repeats)\n",
    "fdcID_pairs = list(itertools.product(FoodDataCentral[\"fdc_id\"],repeat=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8: Create and fit word count vectorizer model to ingredient lists \n",
    "documents = list(FoodDataCentral['ingredients'].values)  #Gather list of ingredient lists from dataset\n",
    "count_vectorizer = CountVectorizer(documents, stop_words='english') #Create Count Vectorizer Model\n",
    "count_vectorizer.fit(documents)  #Fit model to ingredient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9: Transform model to array\n",
    "documents_1 = list(FoodDataCentral['ingredients'].values) \n",
    "vectors = count_vectorizer.transform(documents_1).toarray()\n",
    "np.save(\"\".join((delim_subset,\"_IngredientList_Vectors.npy\")),vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10: Calculate cosine similarity of ingredient lists (Skip to Step 10-11 (Alternate) if available memory is a concern)\n",
    "cos_sim = cosine_similarity(vectors)\n",
    "cos_sim_flat = list(cos_sim)\n",
    "cos_sim_flat = list(chain(*cos_sim_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 11: Create Dataframe with readability differences and cosine similarities\n",
    "analysis_set = pd.DataFrame(fdcID_pairs, columns = [\"fdc_id_1\",\"fdc_id_2\"])\n",
    "analysis_set[\"DaleChallDiff\"] = difference_matrix_dc\n",
    "analysis_set[\"Cosine_similarity\"] = cos_sim_flat\n",
    "analysis_set[\"Flesch_diff\"] = difference_matrix_fl\n",
    "analysis_set[\"Subset\"] = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10-11 (Alternate): In case of low available memory to allocate, the calculations can be done on smaller chunks of the dataset, then combined:\n",
    "\n",
    "#Create Dataframe for containing all values of Dale Chall difference, Flesch Reading Ease difference, and cosine similarity\n",
    "\n",
    "analysis_set = pd.DataFrame(fdcID_pairs, columns = [\"fdc_id_1\",\"fdc_id_2\"])\n",
    "print(analysis_set[\"fdc_id_1\"].head(5))\n",
    "analysis_set[\"DaleChallDiff\"] = difference_matrix_dc\n",
    "analysis_set[\"Flesch_diff\"] = difference_matrix_fl\n",
    "analysis_set[\"Cosine_similarity\"] = np.nan #Needed as a placeholder for coalescing after\n",
    "\n",
    "indices = list(FoodDataCentral[\"fdc_id\"])\n",
    "\n",
    "#Perform Cosine similarity in batches\n",
    "vectors_df = batchCosineSimilarity(vectors,indices,delim_subset,3) \n",
    "vectors_df = pd.read_csv(\"\".join((delim_subset,\"_CosSim_total.csv\")), chunksize=100000)\n",
    "\n",
    "chunks = 1\n",
    "for df in vectors_df:\n",
    "    print(\"Chunk \" + str(chunks))\n",
    "    chunks += 1\n",
    "    df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "    df[\"fdc_id_1\"] = df[\"fdc_id_1\"].astype(\"str\")\n",
    "    df[\"fdc_id_2\"] = df[\"fdc_id_2\"].astype(\"str\")\n",
    "    analysis_set = analysis_set.merge(df, on=[\"fdc_id_1\",\"fdc_id_2\"], how=\"left\",suffixes = ('', '_x'))\n",
    "    analysis_set[\"Cosine_similarity\"] = analysis_set[\"Cosine_similarity\"].combine_first(analysis_set[\"Cosine_similarity_x\"])\n",
    "    analysis_set = analysis_set.drop(columns=\"Cosine_similarity_x\")\n",
    "    analysis_set = analysis_set.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 12: Prepare dataframe for plot generation and Summary Statistics\n",
    "analysis_set.dropna(inplace=True)\n",
    "analysis_set.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "analysis_set.dropna(inplace=True)\n",
    "analysis_set.to_csv(\"\".join((delim_subset,\"_Readability_and_CosineSimilarity_scores.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 13: Get Scatter Plot- Dale Chall diff vs Cosine Similarity\n",
    "plt.scatter(analysis_set[\"DaleChallDiff\"], analysis_set[\"Cosine_similarity\"], c = label_color)\n",
    "plt.xlabel(\"Dale-Chall Index Pairwise difference\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.title(\"Difference In Dale-Chall Index vs Cosine Similarity (\" + delim_subset + \")\")\n",
    "plt.savefig(\"\".join((delim_subset,\"_DaleChall_vs_CosineSimilarity.png\")))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 14: Get Scatter Plot- Dale Chall diff vs Flesch diff\n",
    "plt.scatter(analysis_set[\"DaleChallDiff\"], analysis_set[\"Flesch_diff\"], c = label_color)\n",
    "plt.xlabel(\"Dale-Chall Pairwise difference\")\n",
    "plt.ylabel(\"Flesch Pairwise Difference\")\n",
    "plt.title(\"Difference In Dale-Chall Index vs Difference in Flesch Reading Ease (\" + delim_subset + \")\")\n",
    "plt.savefig(\"\".join((delim_subset,\"_DaleChall_vs_Flesch.png\")))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 15: Get Scatter Plot- Flesch diff vs Cosine Similarity\n",
    "plt.scatter(analysis_set[\"Flesch_diff\"], analysis_set[\"Cosine_similarity\"], c = label_color)\n",
    "plt.xlabel(\"Flesch Pairwise difference\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.title(\"Difference In Flesch Reading Ease vs Cosine Similarity (\" + delim_subset + \")\")\n",
    "plt.savefig(\"\".join((delim_subset,\"_Flesch_vs_CosineSimilarity.png\")))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 16: Get Pearson Correlations (codes: DC = Dale-Chall, FL = Flesch Reading Ease, CS = Cosine similarity)\n",
    "\n",
    "##pearsonr() returns a tuple with two values (from left to right)- Pearson Correlation Coefficient and p-value\n",
    "DC_CS_pearson = pearsonr(analysis_set[\"DaleChallDiff\"], analysis_set[\"Cosine_similarity\"])\n",
    "FL_CS_pearson = pearsonr(analysis_set[\"Flesch_diff\"], analysis_set[\"Cosine_similarity\"])\n",
    "DC_FL_pearson = pearsonr(analysis_set[\"DaleChallDiff\"], analysis_set[\"Flesch_diff\"])\n",
    "Pearson_corrs = [DC_CS_pearson, FL_CS_pearson, DC_FL_pearson]\n",
    "print(\"Dale-Chall vs Cosine Similarity \" + DC_CS_pearson, \"Flesch vs Cosine Similarity \" + DC_CS_pearson, \"Dale-Chall vs Cosine Similarity \" + DC_CS_pearson, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
