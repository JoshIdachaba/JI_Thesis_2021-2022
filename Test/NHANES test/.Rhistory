train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset <- make_csv_dataset(
train_file_path,
field_delim = ",",
batch_size = 5,
num_epochs = 1
)
test_dataset <- train_dataset <- make_csv_dataset(
test_file_path,
field_delim = ",",
batch_size = 5,
num_epochs = 1
)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, CBQ596 ~ ., y = CBQ596)
spec <- feature_spec(train_dataset, CBQ596 ~ ., y = CBQ596)
spec <- spec %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
layer <- layer_dense_features(feature_columns = dense_features(spec))
spec <- fit(spec)
?tf$keras$metrics
tf$keras$metrics
model <- keras_model_sequential() %>%
layer_dense_features(feature_columns = dense_features(spec)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
layer <- layer_dense_features(feature_columns = dense_features(spec))
spec <- feature_spec(train_dataset, survived ~ .) %>%
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
TRAIN_DATA_URL <- "https://storage.googleapis.com/tf-datasets/titanic/train.csv"
TEST_DATA_URL <- "https://storage.googleapis.com/tf-datasets/titanic/eval.csv"
train_file_path <- get_file("train.csv", TRAIN_DATA_URL)
test_file_path <- get_file("eval.csv", TEST_DATA_URL)
train_dataset <- make_csv_dataset(
train_file_path,
field_delim = ",",
batch_size = 5,
num_epochs = 1
)
test_dataset <- train_dataset <- make_csv_dataset(
test_file_path,
field_delim = ",",
batch_size = 5,
num_epochs = 1
)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, survived ~ .) %>%
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
layer()
write.csv(data_test, "hearts_test.csv", row.names = FALSE)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, CBQ596 ~ ., y = CBQ596)
spec <- feature_spec(train_dataset, survived ~ .) %>%
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
layer <- layer_dense_features(feature_columns = dense_features(spec))
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
layer()
model <- keras_model_sequential() %>%
layer_dense_features(feature_columns = dense_features(spec)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
View(spec)
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>%
fit(
train_dataset %>% dataset_use_spec(spec) %>% dataset_shuffle(500),
epochs = 20,
validation_data = test_dataset %>% dataset_use_spec(spec),
verbose = 2
)
spec <- feature_spec(train_dataset, survived ~ .) %>%
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- fit(spec)
model <- keras_model_sequential() %>%
layer_dense_features(feature_columns = dense_features(spec)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>%
fit(
train_dataset %>% dataset_use_spec(spec) %>% dataset_shuffle(500),
epochs = 20,
validation_data = test_dataset %>% dataset_use_spec(spec),
verbose = 2
)
```{r ExampleSetTens, echo=FALSE}
TRAIN_DATA_URL <- "https://storage.googleapis.com/tf-datasets/titanic/train.csv"
TRAIN_DATA_URL <- "https://storage.googleapis.com/tf-datasets/titanic/train.csv"
TEST_DATA_URL <- "https://storage.googleapis.com/tf-datasets/titanic/eval.csv"
train_file_path <- get_file("train.csv", TRAIN_DATA_URL)
test_file_path <- get_file("eval.csv", TEST_DATA_URL)
train_dataset <- make_csv_dataset(
train_file_path,
field_delim = ",",
batch_size = 5,
num_epochs = 1
)
test_dataset <- train_dataset <- make_csv_dataset(
test_file_path,
field_delim = ",",
batch_size = 5,
num_epochs = 1
)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, survived ~ .) %>%
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
layer()
model <- keras_model_sequential() %>%
layer_dense_features(feature_columns = dense_features(spec)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>%
fit(
train_dataset %>% dataset_use_spec(spec) %>% dataset_shuffle(500),
epochs = 20,
validation_data = test_dataset %>% dataset_use_spec(spec),
verbose = 2
)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, survived ~ .) %>%
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- fit(spec)
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
layer()
model <- keras_model_sequential() %>%
layer_dense_features(feature_columns = dense_features(spec)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>%
fit(
train_dataset %>% dataset_use_spec(spec) %>% dataset_shuffle(500),
epochs = 20,
validation_data = test_dataset %>% dataset_use_spec(spec),
verbose = 2
)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, CBQ596 ~ .) %>%
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
layer()
model <- keras_model_sequential() %>%
layer_dense_features(feature_columns = dense_features(spec)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>%
fit(
train_dataset %>% dataset_use_spec(spec) %>% dataset_shuffle(500),
epochs = 20,
validation_data = test_dataset %>% dataset_use_spec(spec),
verbose = 2
)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
layer()
spec <- feature_spec(train_dataset, CBQ596 ~ .) %>% # Make sure formula has correct target variable!
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(CBQ596) %>%
step_indicator_column(CBQ596)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, CBQ596 ~ .) %>% # Make sure formula has correct target variable!
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
train_data <- read.csv("train_data.csv")
test_data <- read.csv("test_data.csv")
unique(test_data$CBQ596)
library(tensorflow)
library(tidyverse)
library(keras)
library(DataExplorer)
library(haven)
library(e1071)
library(caret)
library(ISLR)
library(recipes)
library(mice)
library(doParallel)
library(pROC)
library(stringr)
train_data$CBQ596 <- if_else(train_data$CBQ596 == "X1", 1, 2)
View(train_data)
train_data$CBQ596 <- if_else(train_data$CBQ596 == "X1", 1, 2)
test_data$CBQ596 <- if_else(test_data$CBQ596 == "X1", 1, 2)
write.csv(train_data, "train_data.csv", row.names = FALSE)
write.csv(test_data, "test_data.csv", row.names = FALSE)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, CBQ596 ~ .) %>% # Make sure formula has correct target variable!
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
View(train_data)
View(test_data)
View(test_dataset)
View(spec)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, CBQ596 ~ .) %>% # Make sure formula has correct target variable!
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- feature_spec(train_dataset, CBQ596 ~ .) %>% # Make sure formula has correct target variable!
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard())
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
train_data$CBQ596 <- if_else(train_data$CBQ596 == 1, 1, 0)
test_data$CBQ596 <- if_else(test_data$CBQ596 == 1, 1, 0)
View(test_data)
unique(test_data$CBQ596)
write.csv(train_data, "train_data.csv", row.names = FALSE)
write.csv(test_data, "test_data.csv", row.names = FALSE)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
train_data$cbq596
train_data$CBQ596
View(train_data)
demographics <- read_xpt("DEMO_J.XPT")
diet_behavior <- read_xpt("DBQ_J.XPT")
combined <- demographics %>% left_join(diet_behavior[c(1,40)], by = "SEQN")
library(mice)
#MICE Imputation (mice::mice)
a <- Sys.time()
combined_mice <- mice(combined, m = 5, seed = 2022, method = "cart", maxit = 40)
b = Sys.time()
print("MICE")
print(b-a)
combined_rev <- complete(combined_mice)
combined_rev <- combined_rev %>% select(-c(SDDSRVYR, RIDSTATR, RIDAGEMN))
combined <- combined_rev
combined = combined %>% mutate(CBQ596 = ifelse(is.na(CBQ596) | CBQ596 == 9, 2, 1))
View(combined_rev)
unique(combined$CBQ596)
combined$CBQ596 <- combined$CBQ596 %>% replace(2,0)
View(combined_rev)
View(combined)
combined$CBQ596[combined$CBQ596 == 2] <- 0
View(combined)
combined <- combined %>% mutate_if(is.character, as.factor)
combined <- combined %>% mutate_if(is.factor, make.names)
View(combined)
combined <- combined %>% mutate_if(is.character, as.factor)
combined$SEQN <- as.factor(as.integer(combined$SEQN))
data_index <- createDataPartition(combined[["CBQ596"]], p = 0.7, list = FALSE)
data_train <- combined %>% slice(data_index)
data_test <- combined %>% slice(-data_index)
train_data <- data_train
test_data <- data_test
write.csv(train_data, "train_data.csv", row.names = FALSE)
write.csv(test_data, "test_data.csv", row.names = FALSE)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
train_data$CBQ596
combined_rev <- complete(combined_mice)
combined_rev <- combined_rev %>% select(-c(SDDSRVYR, RIDSTATR, RIDAGEMN))
combined <- combined_rev
combined = combined %>% mutate(CBQ596 = ifelse(is.na(CBQ596) | CBQ596 == 9, 2, 1))
combined$CBQ596 = combined %>% mutate(CBQ596 = ifelse(CBQ596 == 2 | CBQ596 == 9, 0, 1))
combined$CBQ596[combined$CBQ596 == 2] <- 0
combined <- combined %>% mutate_if(is.character, as.factor)
combined <- combined %>% mutate_if(is.factor, make.names)
combined <- combined %>% mutate_if(is.character, as.factor)
combined$SEQN <- as.factor(as.integer(combined$SEQN))
View(combined)
View(combined)
combined_rev <- complete(combined_mice)
combined_rev <- combined_rev %>% select(-c(SDDSRVYR, RIDSTATR, RIDAGEMN))
combined <- combined_rev
View(combined)
combined = combined %>% mutate(CBQ596 = ifelse(is.na(CBQ596) | CBQ596 == 9, 2, 1))
View(combined)
combined_rev <- complete(combined_mice)
combined_rev <- combined_rev %>% select(-c(SDDSRVYR, RIDSTATR, RIDAGEMN))
combined <- combined_rev
View(combined)
combined = combined %>% mutate(CBQ596 = ifelse(is.na(CBQ596) | CBQ596 == 9, 2, 1))
View(combined_rev)
combined <- combined_rev
combined <- combined %>% mutate(CBQ596 = ifelse(is.na(CBQ596) | CBQ596 == 9, 2, 1))
View(combined)
combined <- combined_rev
combined$CBQ596[combined$CBQ596 %in% c(2,9,NA)] <-0
View(combined)
length(is.na(combined$CBQ596))
is.na(combined$CBQ596)
TRUE %in% is.na(combined$CBQ596)
FALSE %in% is.na(combined$CBQ596)
combined_rev <- complete(combined_mice)
combined_rev <- combined_rev %>% select(-c(SDDSRVYR, RIDSTATR, RIDAGEMN))
combined <- combined_rev
combined$CBQ596[combined$CBQ596 %in% c(2,9,NA)] <-0
combined <- combined %>% mutate_if(is.character, as.factor)
combined <- combined %>% mutate_if(is.factor, make.names)
combined <- combined %>% mutate_if(is.character, as.factor)
combined$SEQN <- as.factor(as.integer(combined$SEQN))
View(combined)
data_index <- createDataPartition(combined[["CBQ596"]], p = 0.7, list = FALSE)
data_train <- combined %>% slice(data_index)
data_test <- combined %>% slice(-data_index)
rain_data <- data_train
test_data <- data_test
View(data_test)
train_data <- data_train
test_data <- data_test
write.csv(train_data, "train_data.csv", row.names = FALSE)
write.csv(test_data, "test_data.csv", row.names = FALSE)
train_dataset <- make_csv_dataset("train_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
test_dataset <- make_csv_dataset("test_data.csv", field_delim = ",", batch_size = 5, num_epochs = 1)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, CBQ596 ~ .) %>% # Make sure formula has correct target variable!
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard())
spec <- feature_spec(train_dataset, CBQ596 ~ .) %>% # Make sure formula has correct target variable!
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
View(test_dataset)
TRAIN_DATA_URL <- "https://storage.googleapis.com/tf-datasets/titanic/train.csv"
TEST_DATA_URL <- "https://storage.googleapis.com/tf-datasets/titanic/eval.csv"
train_file_path <- get_file("train.csv", TRAIN_DATA_URL)
test_file_path <- get_file("eval.csv", TEST_DATA_URL)
train_dataset <- make_csv_dataset(
train_file_path,
field_delim = ",",
batch_size = 5,
num_epochs = 1
)
test_dataset <- train_dataset <- make_csv_dataset(
test_file_path,
field_delim = ",",
batch_size = 5,
num_epochs = 1
)
train_dataset %>%
reticulate::as_iterator() %>%
reticulate::iter_next() %>%
reticulate::py_to_r()
spec <- feature_spec(train_dataset, survived ~ .) %>%
step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>%
step_categorical_column_with_vocabulary_list(all_nominal()) %>%
step_indicator_column(all_nominal())
spec <- fit(spec)
layer <- layer_dense_features(feature_columns = dense_features(spec))
knitr::opts_chunk$set(echo = TRUE)
# Current Working Directory
tryCatch({
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}, error=function(cond){message(paste("cannot change working directory"))
})
#Packages Used
library(tensorflow)
library(tidyverse)
library(keras)
library(DataExplorer)
library(haven)
library(e1071)
library(caret)
library(ISLR)
library(recipes)
library(mice)
library(doParallel)
library(pROC)
library(stringr)
installr::updateR()
write.csv(combined_rev, "Imputed Dataset-Test.csv")
install_tensorflow()
knitr::opts_chunk$set(echo = TRUE)
# Current Working Directory
tryCatch({
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}, error=function(cond){message(paste("cannot change working directory"))
})
install.packages("devtools")
library(devtools)
devtools::install_github("rstudio/reticulate")
setwd("~/GitHub/JI_Thesis_2021-2022/NHANES test")
knitr::opts_chunk$set(echo = TRUE)
# Current Working Directory
tryCatch({
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}, error=function(cond){message(paste("cannot change working directory"))
})
devtools::install_github("rstudio/reticulate")
devtools::install_github("rstudio/reticulate")
knitr::opts_chunk$set(echo = TRUE)
# Current Working Directory
tryCatch({
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}, error=function(cond){message(paste("cannot change working directory"))
})
FoodDataCentral_BrandedFood <- read.csv("../Food Database test\FoodData_Central_csv_2021-10-28/branded_food.csv")
FoodDataCentral_BrandedFood <- read.csv("../Food Database test/FoodData_Central_csv_2021-10-28/branded_food.csv")
OpenFoodFacts_Product <- read.csv("../Food Database test/OpenFoodFacts/en.openfoodfacts.org.products")
OpenFoodFacts_Product <- read.csv("../Food Database test/OpenFoodFacts/en.openfoodfacts.org.products.csv")
