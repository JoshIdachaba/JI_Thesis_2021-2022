{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages Used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import readability\n",
    "import time\n",
    "import numbers\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "import itertools\n",
    "from itertools import combinations,chain,product,permutations\n",
    "from batch_test import batchCosineSimilarity\n",
    "import sys\n",
    "\n",
    "\"\"\" The following function performs a cosine similarity analysis of a subset 'subset' of the FDC Global Branded Food Products \n",
    "    Database (GBFPD), assuming it's saved to path as 'branded_food.csv'. The cosine_similarity_analysis function takes \n",
    "    three arguments (all string arguments):\n",
    "    \n",
    "    filename- The path of the file to be opened\n",
    "    \n",
    "    subset- The branded food category to be queried in step 2.\n",
    "    \n",
    "    label_color- The color used for the points in the graph. This can be set to a hex code (e.g., #OOOFFF) or a named color \n",
    "    (Visit https://matplotlib.org/stable/gallery/color/named_colors.html for a list of named colors)\n",
    "\"\"\"\n",
    "\n",
    "def cosine_similarity_analysis(filename, subset, label_color=\"blue\"):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "    filename: The path of the dataset file. This function assumes that this filename corresponds to the FDC branded food dataset\n",
    "    (branded_food.csv by default)\n",
    "    \n",
    "    subset- The subset of the. Can be string, to indicate a section of the dataset where branded_food_category == 'subset', \n",
    "    or numeric, to denote a random sample of size 'subset'.\n",
    "    \n",
    "    label_color: the color used for the points on the scatter plots. This is set to blue by default, but can be any color with a \n",
    "    hex code, or a named color (Visit https://matplotlib.org/stable/gallery/color/named_colors.html for a list of named colors)\n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "    #Step 1: Import Food Data Central Food Products Database \n",
    "    FoodDataCentral = pd.read_csv(filename, low_memory = False)\n",
    "   \n",
    "    #Generate list of branded food categories (Optional, uncomment following three lines to view possible branded food categories for analysis)\n",
    "    #grouped_counts = pd.DataFrame(FoodDataCentral.groupby(['branded_food_category'])['branded_food_category'].count())\n",
    "    #grouped_counts.columns = [\"bfc_count\"]\n",
    "    #grouped_counts.sort_values(by = \"bfc_count\", ascending = False)[50:70]\n",
    "\n",
    "    #Step 2: Get Database subset by branded food category and remove rows with empty values or only non-words \n",
    "    if isinstance(subset, numbers.Number):\n",
    "        delim_subset = \"Random\"\n",
    "        FoodDataCentral = FoodDataCentral.sample(n=subset, random_state=11)\n",
    "    else:\n",
    "        FDC_query = \"\".join((\"branded_food_category == '\",subset,\"'\")) #Note: subset must be in the domain of 'branded_food_category', or else a ValueError is raised.\n",
    "        delim_subset = subset.replace(\" \",\"-\")\n",
    "        FoodDataCentral = FoodDataCentral.query(FDC_query)\n",
    "    \n",
    "    \n",
    "    FoodDataCentral = FoodDataCentral.dropna(subset = ['ingredients'])\n",
    "    FoodDataCentral = FoodDataCentral[FoodDataCentral[\"ingredients\"] != \"---\"]\n",
    "    FoodDataCentral = FoodDataCentral[FoodDataCentral[\"ingredients\"] != \",\"]\n",
    "    \n",
    "    \n",
    "\n",
    "    #Step 3: Calculate and get Readability Scores for FoodData Central ingredient lists\n",
    "    readability_scores = []\n",
    "    for index, row in FoodDataCentral.iterrows():\n",
    "        \n",
    "        #Get ingredient list and convert to lowercase string (required to calculate syllables in readability.getmeasures())\n",
    "        ingredients = row[\"ingredients\"]\n",
    "        ingredients = ingredients.lower()\n",
    "        \n",
    "        # Set ingredient lists with incalculable readability to NA\n",
    "        if pd.isna(ingredients) or ingredients in [\"---\",\",\"]:\n",
    "            curr_record = (row['fdc_id'], row['gtin_upc'], pd.NA,pd.NA)\n",
    "            readability_scores.append(curr_record)\n",
    "\n",
    "        else:\n",
    "            \"\"\"Readability.getmeasures() automatically tokenizes the input using spaces as a delimiter for words and /n as a delimiter for sentences. \n",
    "                The function then calculates and returns a set of readability measures. In this case,\n",
    "                we are getting specific measures from the set (Flesch Reading Ease and Dale-Chall Readability) \"\"\"\n",
    "            \n",
    "            #Prepare data for readability measurement\n",
    "            token_ing = word_tokenize(ingredients)\n",
    "            ingredients = token_ing\n",
    "            \n",
    "            #Get readability measures\n",
    "            measures = readability.getmeasures(ingredients)\n",
    "            curr_record = (row['fdc_id'], row['gtin_upc'], row['branded_food_category'],row['ingredients'],\n",
    "                           measures['readability grades']['Kincaid'],\n",
    "                           measures['readability grades']['FleschReadingEase'],\n",
    "                           measures['readability grades']['DaleChallIndex'],\n",
    "                           measures['sentence info']['words'],\n",
    "                           measures['sentence info']['complex_words_dc'])\n",
    "            readability_scores.append(curr_record)\n",
    "\n",
    "    #Gather data in Pandas DataFrame\n",
    "    readScores_FDC = pd.DataFrame(data = readability_scores, columns = [\"fdc_id\", \"gtin_upc\",\"branded_food_category\",\"ingredients\",\n",
    "                                                                        \"Kincaid_Score\",\"FleschReadingEase\",\"DaleChallIndex\",\n",
    "                                                                        \"num_words\",\"complex_words_dc\"])\n",
    "    #Remove NAs and save dataset to CSV\n",
    "    readScores_FDC = readScores_FDC.dropna()\n",
    "    readScores_FDC.to_csv(\"\".join((delim_subset,\"_FoodData_Central_Readability.csv\")), sep=\",\")\n",
    "    FoodDataCentral = readScores_FDC\n",
    "\n",
    "\n",
    "    #Step 4: Generate Matrix of pairwise differences for Flesch Reading Ease, as a 1-d list\n",
    "    difference_matrix_fl = [[abs(y - x) for x in FoodDataCentral[\"FleschReadingEase\"]] for y in FoodDataCentral[\"FleschReadingEase\"]]\n",
    "    difference_matrix_fl = list(chain(*difference_matrix_fl))\n",
    "\n",
    "    #Step 5: Generate Matrix of pairwise differences for Dale Chall Readability, as a 1-d list\n",
    "    difference_matrix_dc = [[abs(y - x) for x in FoodDataCentral[\"DaleChallIndex\"]] for y in FoodDataCentral[\"DaleChallIndex\"]]\n",
    "    difference_matrix_dc = list(chain(*difference_matrix_dc))\n",
    "\n",
    "    #Step 6: Convert FDC IDs from float to string\n",
    "    FoodDataCentral[\"fdc_id\"] = FoodDataCentral[\"fdc_id\"].astype(\"str\")\n",
    "\n",
    "    #Get FDC indices for referencing matrices (Optional, useful for capturing the domain (range) of IDs)\n",
    "    #fdc_indices = dict(enumerate(FoodDataCentral[\"fdc_id\"]))\n",
    "    #print(fdc_indices)\n",
    "\n",
    "    #Step 7: Create list of FDC ID pairs (w/repeats)\n",
    "    fdcID_pairs = list(itertools.product(FoodDataCentral[\"fdc_id\"],repeat=2))\n",
    "    \n",
    "\n",
    "    #Step 8: Create and fit word count vectorizer model to ingredient lists \n",
    "    documents = list(FoodDataCentral['ingredients'].values)  #Gather list of ingredient lists from dataset\n",
    "    count_vectorizer = CountVectorizer(documents, stop_words='english') #Create Count Vectorizer Model\n",
    "    count_vectorizer.fit(documents)  #Fit model to ingredient list\n",
    "\n",
    "    \n",
    "    #Step 9: Transform model to array\n",
    "    documents_1 = list(FoodDataCentral['ingredients'].values) \n",
    "    vectors = count_vectorizer.transform(documents_1).toarray()\n",
    "    np.save(\"\".join((delim_subset,\"_IngredientList_Vectors.npy\")),vectors)\n",
    "    \n",
    "    \n",
    "\n",
    "    #Step 10: Calculate cosine similarity of ingredient lists\n",
    "    cos_sim = cosine_similarity(vectors)\n",
    "    cos_sim_flat = list(cos_sim)\n",
    "    cos_sim_flat = list(chain(*cos_sim_flat))\n",
    "    \n",
    "    \n",
    "\n",
    "    #Step 11: Create Dataframe with readability differences and cosine similarities\n",
    "    analysis_set = pd.DataFrame(fdcID_pairs, columns = [\"fdc_id_1\",\"fdc_id_2\"])\n",
    "    analysis_set[\"DaleChallDiff\"] = difference_matrix_dc\n",
    "    analysis_set[\"Cosine_similarity\"] = cos_sim_flat\n",
    "    analysis_set[\"Flesch_diff\"] = difference_matrix_fl\n",
    "    analysis_set[\"Subset\"] = subset\n",
    "    \n",
    "    #Step 10-11 (Alternate): In case of low available memory to allocate, the calculations can be done on smaller chunks of the dataset, then combined:\n",
    "    \n",
    "    #Create Dataframe for containing all values of Dale Chall difference, Flesch Reading Ease difference, and cosine similarity\n",
    "    \n",
    "    analysis_set = pd.DataFrame(fdcID_pairs, columns = [\"fdc_id_1\",\"fdc_id_2\"])\n",
    "    print(analysis_set[\"fdc_id_1\"].head(5))\n",
    "    analysis_set[\"DaleChallDiff\"] = difference_matrix_dc\n",
    "    analysis_set[\"Flesch_diff\"] = difference_matrix_fl\n",
    "    analysis_set[\"Cosine_similarity\"] = np.nan #Needed as a placeholder for coalescing after\n",
    "    \n",
    "    indices = list(FoodDataCentral[\"fdc_id\"])\n",
    "    \n",
    "    #Perform Cosine similarity in batches\n",
    "    vectors_df = batchCosineSimilarity(vectors,indices,delim_subset,3) \n",
    "    vectors_df = pd.read_csv(\"\".join((delim_subset,\"_CosSim_total.csv\")), chunksize=100000)\n",
    "    \n",
    "    chunks = 1\n",
    "    for df in vectors_df:\n",
    "        print(\"Chunk \" + str(chunks))\n",
    "        chunks += 1\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "        \n",
    "        df[\"fdc_id_1\"] = df[\"fdc_id_1\"].astype(\"str\")\n",
    "        df[\"fdc_id_2\"] = df[\"fdc_id_2\"].astype(\"str\")\n",
    "        analysis_set = analysis_set.merge(df, on=[\"fdc_id_1\",\"fdc_id_2\"], how=\"left\",suffixes = ('', '_x'))\n",
    "        analysis_set[\"Cosine_similarity\"] = analysis_set[\"Cosine_similarity\"].combine_first(analysis_set[\"Cosine_similarity_x\"])\n",
    "        analysis_set = analysis_set.drop(columns=\"Cosine_similarity_x\")\n",
    "        analysis_set = analysis_set.drop_duplicates()    \n",
    "        \n",
    "    \n",
    "    \n",
    "    #Step 12: Prepare dataframe for plot generation and Summary Statistics\n",
    "    analysis_set.dropna(inplace=True)\n",
    "    analysis_set.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    analysis_set.dropna(inplace=True)\n",
    "    analysis_set.to_csv(\"\".join((delim_subset,\"_Readability_and_CosineSimilarity_scores.csv\")))\n",
    "\n",
    "    #Step 13: Get Scatter Plot- Dale Chall diff vs Cosine Similarity\n",
    "    plt.scatter(analysis_set[\"DaleChallDiff\"], analysis_set[\"Cosine_similarity\"], c = label_color)\n",
    "    plt.xlabel(\"Dale-Chall Index Pairwise difference\")\n",
    "    plt.ylabel(\"Cosine Similarity\")\n",
    "    plt.title(\"Difference In Dale-Chall Index vs Cosine Similarity (\" + delim_subset + \")\")\n",
    "    plt.savefig(\"\".join((delim_subset,\"_DaleChall_vs_CosineSimilarity.png\")))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    #Step 14: Get Scatter Plot- Dale Chall diff vs Flesch diff\n",
    "    plt.scatter(analysis_set[\"DaleChallDiff\"], analysis_set[\"Flesch_diff\"], c = label_color)\n",
    "    plt.xlabel(\"Dale-Chall Pairwise difference\")\n",
    "    plt.ylabel(\"Flesch Pairwise Difference\")\n",
    "    plt.title(\"Difference In Dale-Chall Index vs Difference in Flesch Reading Ease (\" + delim_subset + \")\")\n",
    "    plt.savefig(\"\".join((delim_subset,\"_DaleChall_vs_Flesch.png\")))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    #Step 15: Get Scatter Plot- Flesch diff vs Cosine Similarity\n",
    "    plt.scatter(analysis_set[\"Flesch_diff\"], analysis_set[\"Cosine_similarity\"], c = label_color)\n",
    "    plt.xlabel(\"Flesch Pairwise difference\")\n",
    "    plt.ylabel(\"Cosine Similarity\")\n",
    "    plt.title(\"Difference In Flesch Reading Ease vs Cosine Similarity (\" + delim_subset + \")\")\n",
    "    plt.savefig(\"\".join((delim_subset,\"_Flesch_vs_CosineSimilarity.png\")))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    #Step 16: Get Pearson Correlations (codes: DC = Dale-Chall, FL = Flesch Reading Ease, CS = Cosine similarity)\n",
    "    DC_CS_pearson = pearsonr(analysis_set[\"DaleChallDiff\"], analysis_set[\"Cosine_similarity\"])\n",
    "    FL_CS_pearson = pearsonr(analysis_set[\"Flesch_diff\"], analysis_set[\"Cosine_similarity\"])\n",
    "    DC_FL_pearson = pearsonr(analysis_set[\"DaleChallDiff\"], analysis_set[\"Flesch_diff\"])\n",
    "    Pearson_corrs = [DC_CS_pearson, FL_CS_pearson, DC_FL_pearson]\n",
    "    \n",
    "    return analysis_set\n",
    "    \n",
    "\n",
    "def main():\n",
    "    #cosine_similarity_analysis(\"branded_food.csv\", 6000, \"green\")\n",
    "    #cosine_similarity_analysis(\"branded_food.csv\", \"Rice\", \"blue\")\n",
    "    #cosine_similarity_analysis(\"branded_food.csv\", \"Pasta Dinners\", \"red\")\n",
    "    #cosine_similarity_analysis(\"branded_food.csv\", \"Cream\", \"yellow\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
